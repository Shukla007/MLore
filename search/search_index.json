{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MLore: Unveiling the Magic of AI Education","text":"<p>Unleash the power of AI with MLore, your doorway to a captivating world of education and exploration. Our open-source platform is crafted for learners of all levels, designed to demystify the intricacies of machine learning and data science. Dive into interactive tutorials, hands-on projects, and vibrant community discussions, all aimed at making your AI journey seamless and rewarding. Join us today and embark on a learning experience that transcends boundaries.</p>"},{"location":"#why-mlore","title":"Why MLore?","text":"<ul> <li> Curated Tutorials: Clear and concise guides to complex concepts.</li> <li> Hands-on Projects: Apply your knowledge in real-world scenarios.</li> <li> Community Interaction: Engage with fellow learners and experts.</li> <li> Personalized Learning: Tailored content based on your skill level.</li> <li> Open Source: Collaborate and contribute to the AI community.</li> </ul> <p>Ready to explore the enchanting realm of AI? Join MLore now and unlock a universe of possibilities.</p> <p>Get Started</p>"},{"location":"about/","title":"About","text":"<p>Recently, giscus hit GitHub API's rate limit for one of its users. One of the causes was that giscus always requested a new token from GitHub whenever it makes an API call for unauthenticated users. Each token is valid for 60 minutes, but I didn't cache it at all. As giscus is serverless, I hadn't set up a database (it didn't need one \ud83e\udd37). Thus, I didn't have a proper place to cache the tokens.</p> <p>I thought I could get away by always requesting a fresh token, but unfortunately that wasn't the case. Unusually high traffic would lead giscus to request new tokens too many times in an hour, hitting the rate limit. I decided to set up a database to cache the tokens.</p> <p>I don't make any money off giscus, so free tiers are a life-saver for the project. After a quick research, I found several serverless database platforms with free tiers:</p> <p>PlanetScale: 3 free databases, with 10GB storage, 100 million rows read/month, and 10 million rows written/month per database. Fauna: 100k read ops, 50k write ops, 500k compute ops, 5GB storage. Upstash: 10k commands/day, 100k commands/month, 1GB storage. Supabase: unlimited API requests, 500MB storage.</p>"},{"location":"foundation/","title":"Starting Point","text":""},{"location":"projects/","title":"Projects","text":"<p>Projects</p>"}]}